{"id":"rag3.0-15o","title":"Graphical progress indicator","description":"Add a graphical progress indicator to workflows. This should output a graphical progress indicator to the terminal.\n\n**Challenge:** Figuring out how to quantify progress is non-trivial since:\n- Steps can run in parallel\n- Steps can expand/contract the number of items (flatMap/reduce)\n\n**Next step:** Design a strategy for measuring progress before implementing the indicator.\n\n**Use case:** Particularly useful for batch workflows like embed-documents.\n\n## Implementation Plan\n\n### Executive Summary\n\nThe challenge is to build a progress indicator that accurately reflects pipeline execution despite:\n- **Parallel execution**: Multiple steps may run concurrently with different concurrency levels\n- **Dynamic item counts**: flatMap/reduce operations expand/contract the stream unpredictably\n- **Streaming nature**: Data flows through the pipeline in real-time without knowing totals upfront\n- **Distributed progress**: Progress happens across many steps with different characteristics\n\nThe solution uses a **streaming-aware, step-centric approach** that tracks progress at three levels: individual step item counts, batch windows, and overall pipeline estimates.\n\n---\n\n## Part 1: Progress Tracking Strategy\n\n### 1.1 Core Insights\n\n**Key Challenge**: With dynamic flatMap/reduce operations, we cannot predict total work upfront. A document split into 5 chunks initially might become 50 chunks after a later flatMap operation.\n\n**Solution Approach**: Track progress **per step** and **per window** rather than globally:\n\n1. **Step-Level Tracking**: Each step maintains:\n   - Items processed (input count)\n   - Items yielded (output count)\n   - Expansion ratio (output/input)\n   - Timing metrics (items/sec)\n\n2. **Window-Based Tracking**: For streaming pipelines, use tumbling windows:\n   - 100-item windows collect timing and expansion data\n   - Calculate rolling average throughput\n   - Estimate remaining time based on observed rates\n\n3. **Estimation Model**: \n   - For steps with stable ratios (map, filter): `remaining_time = (input_remaining / current_rate)`\n   - For steps with unknown outputs (flatMap): `remaining_time = buffered_items / completion_rate`\n   - Combine estimates using weighted average (recent data weighted higher)\n\n### 1.2 Handling Parallel Execution\n\nFor parallel map with concurrency limit:\n- Track **in-flight count**: How many items are being processed simultaneously\n- Calculate **parallel efficiency**: Are we utilizing the concurrency limit?\n- Report throughput as: `(completed_items / elapsed_time)`\n\n### 1.3 Handling Dynamic Expansion (flatMap)\n\nFor flatMap operations where output count is unknown:\n- Use **buffering strategy**: Measure expansion ratio on first N items\n- Calculate expansion: `avg_output_per_input` from initial window\n- Estimate: `estimated_total_output = input_count × expansion_ratio`\n\n### 1.4 Multi-Step Coordination\n\nThe pipeline has N steps in sequence:\n- Steps 1 through K-1 have completed: contributes 100% to overall progress\n- Step K is running: contributes (K + progress_ratio) / total_steps\n- Steps K+1 through N are pending: 0% contribution\n\n---\n\n## Part 2: Terminal UI Library Selection\n\n### 2.1 Recommended Approach: Custom Minimal Solution\n\n**Why not use heavy libraries?**\n- `cli-progress`, `progress-stream`, `terminal-kit` add ~100+ dependencies\n- Bun has excellent terminal support built-in\n- Progress indicators need to be **lightweight** for streaming pipelines\n\n**Recommended**: Build a **minimal custom renderer** with:\n- ANSI escape codes for colors and positioning\n- Single-line or multi-line modes\n- No external dependencies beyond built-ins\n\n### 2.2 UI/UX Considerations\n\n**Design principles:**\n1. **Minimal distraction**: Single-line mode for quiet execution\n2. **Hierarchical**: Show overall progress, then current step details\n3. **Information density**: Show rate, ETA, item counts without clutter\n4. **Color coding**:\n   - Green: Completed steps\n   - Yellow: In-progress (current)\n   - Blue: Pending\n   - Red: Errors\n   - Gray: Disabled info\n5. **Responsive**: Update every 100-200ms (don't thrash terminal)\n\n**Display options:**\n- **Compact**: Single line per step, show only active steps\n- **Verbose**: Full details for debugging\n- **Silent**: Only log final stats (production mode)\n\n---\n\n## Part 3: Pipeline Integration Architecture\n\n### 3.1 Integration Points\n\nThe ProgressTracker needs hooks into:\n\n1. **StreamingPipeline.execute()** - Wrap execution with progress tracking\n2. **Individual streaming steps** - Intercept yields to count items\n3. **Parallel map operations** - Track in-flight concurrency\n4. **Batch operations** - Count windows yielded\n5. **Error handling** - Track failures per step\n\n### 3.2 Minimal Integration Pattern\n\nIntegration should be added to:\n- `StreamingPipeline` class with `withProgress()` method\n- Streaming generators to track item counts\n- Parallel operations to track concurrency\n\n---\n\n## Part 4: Edge Cases and Challenges\n\n### 4.1 Unknown Total Items (flatMap Expansion)\n\n**Challenge**: Cannot know total count when flatMap expands items dynamically\n\n**Solution**:\n- Calculate expansion ratio from first 100 items\n- Apply ratio to remaining items: `estimated_remaining = input_remaining × avg_expansion`\n- Refine estimate as more data arrives\n- Show \"estimated\" label on percentage to indicate uncertainty\n\n### 4.2 Parallel Execution Order Unpredictability\n\n**Challenge**: With `ordered: false` in parallelMap, items complete out of order\n\n**Solution**:\n- Track items **input** vs **output** separately\n- Show progress as \"X items processed\" rather than relying on sequential indices\n- For in-flight work, show: \"N/M batches completed\" (what we know for sure)\n\n### 4.3 Highly Variable Processing Times\n\n**Challenge**: Step A processes 1K items/sec, Step B processes 10 items/sec → bottleneck shifts\n\n**Solution**:\n- Use exponential moving average (EMA) for rates: `new_rate = 0.3 × current + 0.7 × prev`\n- Track P50, P95 latencies to show variance\n- ETA reflects actual bottleneck, not average\n\n### 4.4 Small Batches and Early Termination\n\n**Challenge**: With `take(N)` operator, pipeline stops early\n\n**Solution**:\n- Listen for early termination signals\n- Show \"completed early\" message\n- Calculate final throughput from actual execution\n\n### 4.5 Memory-Constrained Environments\n\n**Challenge**: Tracking every item for huge streams causes memory issues\n\n**Solution**:\n- Sample-based tracking: Track every Nth item (configurable)\n- Derive full counts from samples: `estimated = sampled_count × (1 / sample_rate)`\n- Keep only rolling window of recent samples (last 1K items)\n\n---\n\n## Part 5: Step-by-Step Implementation Plan\n\n### Phase 1: Core Infrastructure\n\n**Step 1.1**: Create progress tracker module\n- `/src/core/pipeline/progress/tracker.ts` - ProgressTracker class\n- `/src/core/pipeline/progress/types.ts` - Type definitions\n- `/src/core/pipeline/progress/index.ts` - Exports\n\n**Step 1.2**: Create terminal renderer\n- `/src/core/pipeline/progress/renderer.ts` - ProgressRenderer class\n- `/src/core/pipeline/progress/formatting.ts` - Helper functions for formatting\n- Support compact/verbose/silent modes\n\n**Step 1.3**: Unit tests\n- `/src/core/pipeline/progress/tracker.test.ts`\n- `/src/core/pipeline/progress/renderer.test.ts`\n\n### Phase 2: Integration with Streaming Pipeline\n\n**Step 2.1**: Add progress tracking hooks to StreamingPipeline\n- Modify `StreamingPipeline.withProgress()` method\n- Add progress parameter to `execute()`\n- Track step lifecycle (start, item processed/yielded, complete)\n\n**Step 2.2**: Integrate with streaming generators\n- Wrap async generators in progress-tracking generators\n- Modify `streaming/generators.ts` to accept optional tracker\n- Track map, filter, flatMap, batch, window operations\n\n**Step 2.3**: Integrate with parallel operations\n- Modify `streaming/parallel.ts` to track in-flight operations\n- Record concurrency utilization\n- Track completion rates\n\n**Step 2.4**: Integration tests\n- `/src/core/pipeline/streaming/progress.integration.test.ts`\n- Test with embed-documents workflow\n- Verify accuracy of estimates\n\n### Phase 3: UI Polish and Options\n\n**Step 3.1**: Progress options and configuration\n- Create `ProgressOptions` interface with:\n  - `enabled: boolean`\n  - `mode: 'compact' | 'verbose' | 'silent'`\n  - `updateIntervalMs: number`\n  - `samplingRate: number` (for large streams)\n  - `showTimings: boolean`\n\n**Step 3.2**: Color and formatting enhancements\n- Multi-step display with status indicators\n- Error highlighting\n- Final summary statistics\n\n**Step 3.3**: Documentation\n- Progress tracking architecture doc\n- Usage examples\n- Performance impact notes\n\n### Phase 4: Testing and Validation\n\n**Step 4.1**: Real-world validation\n- Run embed-documents with progress tracking\n- Measure accuracy of ETA estimates\n- Compare actual vs predicted times across 10+ runs\n\n**Step 4.2**: Performance validation\n- Measure overhead of progress tracking\n- Ensure \u003c5% CPU overhead\n- Memory usage stays constant (bounded by sampling)\n\n**Step 4.3**: Edge case testing\n- Very fast operations (1K+ items/sec)\n- Very slow operations (1 item/sec)\n- Highly variable latencies\n- Early termination with `take()`\n- High concurrency (100+)\n\n**Step 4.4**: Documentation and examples\n- Add progress example to `/src/core/pipeline/examples/`\n- Update embed-documents to show usage\n- Add to CLAUDE.md as documented feature\n\n---\n\n## Part 6: Key Implementation Details\n\n### 6.1 File Structure\n\n```\nsrc/core/pipeline/progress/\n├── index.ts                    # Exports\n├── types.ts                    # Interfaces: ProgressTracker, StepProgress, ProgressEvent\n├── tracker.ts                  # ProgressTracker implementation (300-400 lines)\n├── renderer.ts                 # ProgressRenderer implementation (250-350 lines)\n├── formatting.ts               # ANSI codes, bar rendering, time/rate formatting (150 lines)\n├── sampling.ts                 # Sample-based tracking for memory efficiency (100 lines)\n├── tracker.test.ts             # Unit tests (250+ lines)\n├── renderer.test.ts            # Unit tests (200+ lines)\n└── README.md                   # Architecture documentation\n```\n\n### 6.2 Key Classes and Methods\n\n**ProgressTracker**:\n```typescript\nclass ProgressTracker {\n  constructor(options: ProgressOptions) { }\n  \n  // Lifecycle\n  recordStepStarted(stepName: string, index: number, total: number): void\n  recordStepCompleted(stepName: string): void\n  recordError(stepName: string, error: Error): void\n  \n  // Item tracking\n  recordItemProcessed(stepName: string, count: number): void\n  recordItemYielded(stepName: string, count: number): void\n  \n  // Parallel tracking\n  recordParallelInFlight(stepName: string, count: number, limit: number): void\n  \n  // Batch tracking\n  recordBatchCompleted(stepName: string, batchId: number, size: number): void\n  \n  // Progress queries\n  getStepProgress(stepName: string): StepProgress\n  getOverallProgress(): OverallProgress\n  \n  // Events\n  subscribe(listener: ProgressListener): () =\u003e void // Unsubscribe\n  \n  // Summary\n  generateFinalSummary(): string\n}\n```\n\n**ProgressRenderer**:\n```typescript\nclass ProgressRenderer {\n  constructor(stream: WritableStream, options: RenderOptions) { }\n  \n  render(progress: ProgressTracker): void\n  \n  private formatCompactMode(): string\n  private formatVerboseMode(): string\n  private renderBar(ratio: number): string\n  private clearLine(): void\n}\n```\n\n### 6.3 Measurement Strategy\n\n**What to track per step:**\n- Input items: Count via `recordItemProcessed()`\n- Output items: Count via `recordItemYielded()`\n- Timing: Calculate `inputRate` and `outputRate` (items/sec)\n- Expansion: `outputCount / inputCount` (ratio)\n- In-flight: For parallel ops, current count/limit\n\n**Update frequency:**\n- Emit events every 100-200ms (configurable)\n- Update renderer only when subscribed\n- Avoid thrashing terminal with too many updates\n\n**Memory management:**\n- Keep only last N measurements per step (default: 1000)\n- Use circular buffer for timing statistics\n- Free completed step data after summary\n\n---\n\n## Part 7: Example Usage\n\n```typescript\nimport { StreamingPipeline } from './streaming-builder';\nimport { embedDocuments } from './workflows/embed-documents';\n\n// Basic usage with progress\nconst pipeline = StreamingPipeline.start\u003cDocument\u003e()\n  .map('parsed', parseDocument)\n  .batch('batches', 50)\n  .map('embedded', embedBatch, { parallel: true, concurrency: 5 })\n  .flatMap('flattened', batch =\u003e batch)\n  .withProgress({\n    enabled: true,\n    mode: 'compact',\n    updateIntervalMs: 200,\n  });\n\nfor await (const doc of pipeline.execute(documents)) {\n  // Terminal shows:\n  // Pipeline: [████████\u003e  ] 67% | 2.3K items/sec | ETA 45s\n  // └─ parsed     : [██████████] 100% ✓\n  // └─ batches    : [██████████] 100% ✓\n  // └─ embedded   : [████████\u003e  ] 80% | 150 batches/sec\n  // └─ flattened  : [\u003e         ] 5% | 2.3K items/sec\n  console.log(doc.id);\n}\n\n// Or in embed-documents workflow\nconst result = await embedDocuments({\n  folderPath: './docs',\n  showProgress: true, // Add to config schema\n});\n```\n\n---\n\n## Critical Files for Implementation\n\n- `/home/jeffutter/src/rag3.0/src/core/pipeline/streaming-builder.ts` - Extend with progress support\n- `/home/jeffutter/src/rag3.0/src/core/pipeline/streaming/parallel.ts` - Add concurrency tracking\n- `/home/jeffutter/src/rag3.0/src/core/pipeline/streaming/generators.ts` - Wrap generators for counting\n- `/home/jeffutter/src/rag3.0/src/core/pipeline/types.ts` - Extend StepMetadata for progress\n- `/home/jeffutter/src/rag3.0/src/workflows/embed-documents.ts` - Example integration\n\n---\n\n## Summary\n\nThis plan provides a **streaming-first, step-centric progress tracking system** that:\n\n1. **Handles dynamic expansion** through rolling ratio estimates\n2. **Tracks parallel execution** with concurrency awareness  \n3. **Provides accurate ETAs** using exponential moving averages of actual rates\n4. **Minimizes overhead** with sampling and bounded memory usage\n5. **Integrates cleanly** into the existing Pipeline architecture\n6. **Offers flexible UI** with compact/verbose/silent modes\n7. **Requires no external dependencies** (uses only Bun builtins + ANSI codes)\n\nThe implementation is modular, testable, and production-ready.\n","status":"closed","priority":2,"issue_type":"feature","owner":"jeff@jeffutter.com","created_at":"2026-01-18T12:21:59.663074086-06:00","created_by":"Jeffery Utter","updated_at":"2026-01-18T13:12:17.896241972-06:00","closed_at":"2026-01-18T13:12:17.896241972-06:00","close_reason":"Closed","labels":["planned"]}
{"id":"rag3.0-pv1","title":"Clean up remaining logs in tests","description":"There are still some logs outputting in tests, particularly when running `bun test -t '.*Pipeline Integration Tests.*'` clean these up\n\n## Implementation Plan\n\n### Root Cause Analysis\n\nThe pipeline logs are appearing during tests for the following reasons:\n\n1. **Logger Level Detection Issue**: The test preload script attempts to silence logs by setting `LOG_LEVEL=silent`, but this is not working correctly in all scenarios.\n\n2. **Logger State Problem**: When using `bun test -t \".*Pattern.*\"` across all files (which loads multiple test files), the logger module is loaded at different times and in different contexts, causing the level-setting logic in `test-preload.ts` to be ineffective.\n\n3. **Formatter Stream Bypass**: The `createFormatterStream` function in `logger.ts` writes directly to `process.stdout` without checking if the logger's level should suppress the output. Even when Pino's level is set to \"silent\", the formatter stream writes before Pino's level check applies.\n\n4. **Direct Console Calls**: There are direct `console.error()` and `console.warn()` calls in:\n   - `src/steps/ai/generate-embeddings-for-batch.ts` (lines 71, 88)\n   - `src/core/pipeline/streaming/metadata.ts` (line 167)\n\n5. **Environment Detection Gap**: The current logic checks `isDev` (not production) and `isBunTest`, but the timing of when these are evaluated doesn't guarantee the test environment is properly detected when tests are loaded via pattern matching.\n\n### Strategy\n\n**Phase 1: Fix Logger-Level Detection in Formatter Stream**\n- Modify `createFormatterStream` in `logger.ts` to respect the logger's level setting\n- Add a level check before writing to stdout\n- Ensure the formatter only outputs logs at the configured level\n\n**Phase 2: Fix Test Preload Timing**\n- Ensure `test-preload.ts` properly silences logs regardless of when modules are loaded\n- Add a more robust check for test environment that doesn't rely on module load order\n- Consider using a lazy level check rather than setting at load time\n\n**Phase 3: Replace Direct Console Calls**\n- Replace `console.error()` and `console.warn()` in non-test code with logger calls\n- For debugging/error handling, use the logger with appropriate levels\n- Preserve console calls only for critical unrecoverable errors where logging infrastructure might be unavailable\n\n**Phase 4: Add Console Suppression Verification**\n- Ensure the test preload console suppression (lines 28-44 in test-preload.ts) is actually working\n- Consider adding a verification log to confirm suppression is active\n- Add a guard to prevent tests from explicitly calling console.log/warn/info\n\n### Files That Need Changes\n\n1. **`src/core/logging/logger.ts`**\n   - Add level checking to the logger initialization\n   - Modify how the formatter stream respects levels\n   - Ensure silent level actually suppresses output\n\n2. **`src/core/logging/formatter.ts`**\n   - Add level checking to `createFormatterStream` function\n   - Only write to stdout if the log level should be output\n   - Import necessary level constants\n\n3. **`src/test-preload.ts`**\n   - Enhance the level detection logic\n   - Ensure logger reference is properly updated after being created\n   - Add verification that console suppression is working\n\n4. **`src/steps/ai/generate-embeddings-for-batch.ts`**\n   - Replace `console.error()` calls (lines 71, 88) with logger or error handling\n   - Consider if these are meant for debugging or actual error reporting\n\n5. **`src/core/pipeline/streaming/metadata.ts`**\n   - Replace `console.warn()` call (line 167) with logger.warn()\n   - Import logger from logging module\n   - Preserve the warning but channel it through proper logging\n\n### Implementation Order\n\n1. Fix the formatter stream to respect log levels (highest impact)\n2. Enhance test-preload.ts to ensure proper level setting\n3. Replace direct console calls with logger calls\n4. Test with the specific command: `bun test -t '.*Pipeline Integration Tests.*'`\n5. Verify no logs appear without explicit LOG_LEVEL environment variable\n\n### Debugging Considerations\n\n- Some developers may want to see logs during specific test runs using `LOG_LEVEL=info bun test ...`\n- The current mechanism supports this via environment variable - preserve this capability\n- Consider adding a guide in documentation about enabling debug logs with: `TEST_VERBOSE=1 bun test ...`\n- Keep console.error suppression conditional (currently lines 34-35 in test-preload.ts already preserve it)\n\n### Verification Strategy\n\nTest cases should verify:\n- `bun test` produces no logs\n- `bun test -t \".*Pipeline Integration Tests.*\"` produces no logs  \n- `LOG_LEVEL=info bun test` shows logs as expected\n- `TEST_VERBOSE=1 bun test` shows console output when explicitly enabled\n- Individual test file execution remains unaffected","status":"closed","priority":2,"issue_type":"task","owner":"jeff@jeffutter.com","created_at":"2026-01-18T12:37:35.614681018-06:00","created_by":"Jeffery Utter","updated_at":"2026-01-18T17:45:46.286403664-06:00","closed_at":"2026-01-18T17:45:46.286403664-06:00","close_reason":"Closed","labels":["planned"]}
{"id":"rag3.0-t6x","title":"Investigate duplicate embedding code","description":"There appears to be duplication between two embedding-related files:\n\n1. **src/lib/embeddings.ts** - Utility function `generateEmbeddings()`\n   - Handles batch processing (multiple texts in single API call)\n   - Full Zod schema validation\n   - Sorts results by index\n   - Verifies response count matches input count\n\n2. **src/retrieval/embedding.ts** - Pipeline step `createEmbeddingStep()`\n   - Processes single text at a time\n   - Uses type assertion instead of Zod\n   - Has retry configuration\n   - Integrates with pipeline infrastructure\n\n**Task:** Determine if these are truly duplicates or serve different purposes. If duplicates, remove the one that's less aligned with the codebase architecture (likely consolidate into the utility function and have the step use it).\n\n## Implementation Plan\n\n### Executive Summary\n\nThe two files are **NOT true duplicates** but rather serve different purposes along the pipeline architecture. However, `src/retrieval/embedding.ts` is **unused and should be deprecated**. The codebase has already migrated to the recommended pattern (utility function + steps that use it) and the `createEmbeddingStep` factory function exists but isn't utilized anywhere.\n\n### Analysis Findings\n\n**Are They Duplicates?**\n\nNo, not technically duplicates, but closely related with different concerns:\n\n1. **`src/lib/embeddings.ts` (Utility Function)**\n   - Pure business logic layer\n   - Batch processing (multiple texts in one call)\n   - Full Zod validation (request and response schemas)\n   - Error handling and validation\n   - NO retry logic (that's a pipeline concern)\n   - NO logging (that's a step concern)\n   - **Correctly placed in `src/lib/`**\n\n2. **`src/retrieval/embedding.ts` (Step Factory)**\n   - Pipeline integration layer\n   - Single-text processing (takes `text: string`)\n   - Type assertions instead of validation\n   - Retry configuration (3 attempts, 1000ms backoff)\n   - Logging of events\n   - **Incorrectly placed - should be in `src/steps/` if it existed**\n   - **NOT ACTUALLY USED ANYWHERE**\n\n### Historical Context\n\nFrom git history:\n- **7f5d084 (Dec 2025)**: Original implementation included `createEmbeddingStep` in `src/retrieval/embedding.ts`\n- **e7cae19 (Dec 22, 2025)**: Architecture rule established: \"Don't reference steps from inside other steps, extract common bits to utility functions\"\n- **0c70cc4 (Dec 23, 2025)**: RAG search refactored to use `generateEmbeddings` utility directly instead of any step\n\nThis shows the codebase **already migrated away** from the step-based approach to use the utility-based approach.\n\n### Current Usage\n\n**`generateEmbeddings` utility is actively used:**\n- `src/tools/rag-search.ts` - Direct API call (line 180)\n- `src/steps/ai/generate-embeddings.ts` - Step wrapper around utility (tested and exported)\n- `src/steps/ai/generate-embeddings-for-batch.ts` - Step factory using utility\n- `src/workflows/embed-documents.ts` - Workflow using the batch step\n\n**`createEmbeddingStep` is NOT used:**\n- Only type import (`EmbeddingConfig`) in `src/tools/rag-search.ts`\n- No step instance is ever created from this factory\n- No tests for this function\n\n### Consolidation Strategy\n\n**Phase 1: Assessment \u0026 Documentation**\n1. Document that `createEmbeddingStep` is unused legacy code\n2. Verify that `generateEmbeddings` utility covers all use cases\n3. Confirm `EmbeddingConfig` type is needed for rag-search.ts\n\n**Phase 2: Refactoring**\n1. **Move `EmbeddingConfig` type** from `src/retrieval/embedding.ts` to `src/lib/embeddings.ts`\n   - This type logically belongs with the utility function it configures\n   - Single source of truth for configuration\n\n2. **Update imports** in dependent files:\n   - `src/tools/rag-search.ts`: Change import from `src/retrieval/embedding` to `src/lib/embeddings`\n\n3. **Deprecate `src/retrieval/embedding.ts`**\n   - Marked for removal in next major version\n   - Option A: Add deprecation notice and keep for backwards compatibility\n   - Option B: Remove entirely if no external consumers\n\n4. **Add documentation** to `src/lib/embeddings.ts`:\n   - Explain that this is the single source for embedding operations\n   - Reference the singleton `EmbeddingConfig` type\n   - Note that `createEmbeddingStep` in `src/retrieval/embedding.ts` is deprecated\n\n**Phase 3: Testing**\n1. Verify `src/steps/ai/generate-embeddings.test.ts` still passes\n2. Run full test suite to ensure no regressions\n3. No new tests needed (coverage already exists)\n\n**Phase 4: Cleanup**\n1. Remove `src/retrieval/embedding.ts` after confirming it's unused\n2. Update CLAUDE.md example if it references the old pattern\n3. Create an issue documenting the architectural migration\n\n### Files That Need Changes\n\n1. **`src/lib/embeddings.ts`** - Core utility function; will receive `EmbeddingConfig` type from `src/retrieval/embedding.ts`\n\n2. **`src/tools/rag-search.ts`** - Updates import statement for `EmbeddingConfig`; currently imports from wrong location\n\n3. **`src/retrieval/embedding.ts`** - File to deprecate/remove; contains unused `createEmbeddingStep` factory and `EmbeddingConfig` type\n\n4. **`src/steps/ai/generate-embeddings.ts`** - Already correctly uses the utility; may need minor docs update for clarity\n\n5. **`docs/architecture/steps-and-workflows.md`** - Update if it has examples referencing the old pattern\n\n### Implementation Steps\n\n**Step 1: Extract Type Definition**\n- Copy `EmbeddingConfig` interface from `src/retrieval/embedding.ts` to `src/lib/embeddings.ts`\n- Add export statement for the type\n\n**Step 2: Update Imports**\n- Update `src/tools/rag-search.ts` to import `EmbeddingConfig` from `src/lib/embeddings` instead of `src/retrieval/embedding`\n\n**Step 3: Add Documentation**\n- Add comment to `src/lib/embeddings.ts` noting this is the canonical location for all embedding operations\n- Add deprecation notice to `src/retrieval/embedding.ts` explaining the migration\n\n**Step 4: Verify Tests**\n- Run `bun test` to ensure all tests still pass\n- Confirm no broken imports\n\n**Step 5: Cleanup (Optional in first PR)**\n- Remove `src/retrieval/embedding.ts` in a follow-up PR\n- Document the change in commit message and issue\n\n### Expected Outcomes\n\n**After Consolidation:**\n1. **Single source of truth**: All embedding operations go through `src/lib/embeddings.ts`\n2. **Clear architecture**: Follows utility → step → workflow pattern consistently\n3. **No duplicate code**: Only one implementation of embedding API calls\n4. **Better maintainability**: Changes to embedding logic only happen in one place\n5. **Cleaner imports**: No circular or confusing import patterns\n\n### Migration Path for Consumers:\n```typescript\n// OLD (don't use)\nimport type { EmbeddingConfig } from \"../retrieval/embedding\";\nimport { createEmbeddingStep } from \"../retrieval/embedding\";\n\n// NEW (use this)\nimport type { EmbeddingConfig } from \"../lib/embeddings\";\nimport { generateEmbeddings } from \"../lib/embeddings\";\n\n// If you need a step, create one at the workflow level:\nconst embeddingStep = createStep(\"embeddings\", async ({ input }) =\u003e {\n  const embeddings = await generateEmbeddings(\n    [input.text],\n    config.endpoint,\n    config.model,\n    config.apiKey\n  );\n  return embeddings[0];\n});\n```\n\n### Risk Assessment\n\n**Low Risk:** \n- `createEmbeddingStep` is already unused\n- The utility function is already the canonical implementation\n- Changes are localized to type imports only\n- Full test coverage exists for embedding functionality\n\n**Mitigation:**\n- Run complete test suite before and after changes\n- Keep a deprecation period for external consumers\n- Document breaking changes clearly","status":"closed","priority":2,"issue_type":"task","owner":"jeff@jeffutter.com","created_at":"2026-01-18T12:29:32.187432406-06:00","created_by":"Jeffery Utter","updated_at":"2026-01-18T13:16:11.362156804-06:00","closed_at":"2026-01-18T13:16:11.362156804-06:00","close_reason":"Consolidated duplicate embedding code. Analysis confirmed that src/retrieval/embedding.ts contained an unused createEmbeddingStep function - the codebase had already migrated to using the src/lib/embeddings.ts utility function. Moved EmbeddingConfig interface to src/lib/embeddings.ts, updated import in src/tools/rag-search.ts, and removed the deprecated file. All 1118 tests pass.","labels":["planned"]}
