# LLM Orchestrator - Environment Variables Example
# Copy this file to .env and fill in your values

# ============================================================================
# LLM Configuration (Required)
# ============================================================================

# Base URL for your LLM API endpoint
# Options:
#   - llama.cpp: http://localhost:8080/v1
#   - Ollama: http://localhost:11434/v1
#   - OpenAI: https://api.openai.com/v1
#   - vLLM: http://localhost:8000/v1
LLM_BASE_URL=http://localhost:8080/v1

# Model to use for chat completions
# Examples:
#   - llama.cpp/Ollama: qwen2.5:7b, llama3:8b, mistral:latest
#   - OpenAI: gpt-4, gpt-3.5-turbo
LLM_MODEL=qwen2.5:7b

# API key (optional, only needed for OpenAI or services requiring auth)
# LLM_API_KEY=sk-...

# Request timeout in milliseconds (optional, default: 120000)
# LLM_TIMEOUT=120000

# ============================================================================
# Embedding Configuration (Required for RAG)
# ============================================================================

# Base URL for embedding API endpoint
# Often the same as LLM_BASE_URL for local setups
EMBEDDING_BASE_URL=http://localhost:8080/v1

# Embedding model to use
# Examples:
#   - llama.cpp/Ollama: nomic-embed-text, all-minilm:latest
#   - OpenAI: text-embedding-3-small, text-embedding-ada-002
#   - Qwen3: qwen3-embedding (supports instructions)
EMBEDDING_MODEL=nomic-embed-text

# API key for embedding service (optional)
# EMBEDDING_API_KEY=sk-...

# Enable instruction-based embeddings (optional, for models like qwen3-embedding)
# When enabled, queries are formatted as: "Instruct: {instructions}\nThe current date is: {date}\nQuery: {query}"
# Default: false
# EMBEDDING_USE_INSTRUCTIONS=true

# Custom instructions for embedding queries (optional)
# Only used when EMBEDDING_USE_INSTRUCTIONS=true
# Default: "Given a document search query, retrieve relevant documents that answer the query. Pay special attention to date and time ranges mentioned in the query, rank those documents higher."
# EMBEDDING_INSTRUCTIONS="Your custom instructions here"

# ============================================================================
# Reranker Configuration (Optional for RAG)
# ============================================================================

# Base URL for reranking API endpoint
# Used to rerank search results for improved relevance
RERANKER_BASE_URL=https://llama.home.jeffutter.com/v1

# Reranker model to use (optional)
# Examples:
#   - bge-reranker-v2-m3
#   - Qwen3: qwen3-reranker (supports instructions)
# RERANKER_MODEL=bge-reranker-v2-m3

# API key for reranker service (optional)
# RERANKER_API_KEY=your-key-here

# Enable instruction-based reranking (optional, for models like qwen3-reranker)
# When enabled, documents are formatted as: "<Instruct>: {instructions}\n<Query>: {query}\n<Document>: {document}"
# Default: false
# RERANKER_USE_INSTRUCTIONS=true

# Custom instructions for reranking (optional)
# Only used when RERANKER_USE_INSTRUCTIONS=true
# Default: "Given a query and a document, determine how relevant the document is to answering the query. Pay special attention to date and time ranges mentioned in the query."
# RERANKER_INSTRUCTIONS="Your custom instructions here"

# ============================================================================
# Vector Database Configuration (Required for RAG)
# ============================================================================

# Qdrant server URL
QDRANT_URL=http://localhost:6333

# Qdrant API key (optional, for Qdrant Cloud or secured instances)
# QDRANT_API_KEY=your-key-here

# Default collection name for RAG searches
QDRANT_COLLECTION=rag_store

# ============================================================================
# Logging Configuration (Optional)
# ============================================================================

# Log level: trace, debug, info, warn, error, fatal
# Default: info
LOG_LEVEL=info

# Environment (affects log formatting)
# development = compact/custom formatted logs
# production = JSON logs
NODE_ENV=development

# Log format for development (only applies when NODE_ENV=development)
# Options:
#   compact - Single line, timestamp/level dim, event bright (default, recommended)
#   hybrid  - Event on first line, details indented below (2 lines per log)
#   minimal - Ultra-compact with minimal metadata
#   pretty  - Traditional pino-pretty multi-line format (most verbose)
# Default: compact
# LOG_FORMAT=compact

# Sanitize logs by truncating large objects/arrays (recommended for readability)
# Set to false when you need full payloads (e.g., testing API requests in curl)
# Default: true
# LOG_SANITIZE=true

# Maximum array items to show in logs (default: 3)
# Useful for limiting verbose arrays like search results or embeddings
# LOG_MAX_ARRAY_LENGTH=3

# Maximum string length in logs (default: 500)
# Strings longer than this will be truncated with a character count
# LOG_MAX_STRING_LENGTH=500

# Maximum object depth in logs (default: 3)
# Objects deeper than this will show keys only
# LOG_MAX_DEPTH=3

# ============================================================================
# Server Configuration (Optional, for HTTP server mode)
# ============================================================================

# Port for HTTP server
# PORT=3000

# Host to bind to
# HOST=0.0.0.0

# ============================================================================
# Testing & Development
# ============================================================================

# Path to config file (optional, overrides default config.json)
# CONFIG_FILE=./config.json
